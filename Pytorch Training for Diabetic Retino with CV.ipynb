{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is my first major take on image classification competition and I have tried to put forth all the learnings from my deep learning course.\n",
    "\n",
    "* References:\n",
    "\n",
    "1.https://www.kaggle.com/abhishek/very-simple-pytorch-training-0-59\n",
    "\n",
    "2.https://www.kaggle.com/super13579/pytorch-nn-cyclelr-k-fold-0-897-lightgbm-0-899\n",
    "\n",
    "3.https://www.kaggle.com/artgor/basic-eda-and-baseline-pytorch-model/data\n",
    "\n",
    "4.https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter\n",
    "\n",
    "5.https://github.com/anandsaha/pytorch.cyclic.learning.rate/blob/master/cls.py\n",
    "\n",
    "6.Various discussions in the forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretrained-pytorch-models', 'earlystoppingpytorch', 'aptos2019-blindness-detection']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import time\n",
    "import seaborn as sns\n",
    "import random\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image,ImageFile\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset,DataLoader,Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "import albumentations\n",
    "from albumentations import torch as AT\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,KFold\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import gc\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "## early stopping package:\n",
    "package='../input/earlystoppingpytorch/early-stopping-pytorch/early-stopping-pytorch'\n",
    "sys.path.append(package)\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Import the labels,\n",
    "train_labels=pd.read_csv(\"../input/aptos2019-blindness-detection/train.csv\")\n",
    "test=pd.read_csv(\"../input/aptos2019-blindness-detection/test.csv\")\n",
    "sample=pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  000c1434d8d7          2\n",
       "1  001639a390f0          4\n",
       "2  0024cdab0c1e          1\n",
       "3  002c21358ce6          0\n",
       "4  005b95c28852          0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3662"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels['id_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "2     999\n",
       "1     370\n",
       "4     295\n",
       "3     193\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - No DR\n",
    "\n",
    "1 - Mild\n",
    "\n",
    "2 - Moderate\n",
    "\n",
    "3 - Severe\n",
    "\n",
    "4 - Proliferative DR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of images with No DR is 1805 followed by Moderate DR and Mild DR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test['id_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS=5\n",
    "BATCH_SIZE=32\n",
    "IMAGE_SIZE=224\n",
    "data_dir=\"../input/aptos2019-blindness-detection/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x,valid_x,train_y,valid_y=train_test_split(train_labels,train_labels['diagnosis'],test_size=0.2,shuffle=train_labels['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x.shape,train_y.shape,valid_x.shape,valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspired from - https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter\n",
    "def display_samples(df, columns=4, rows=3):\n",
    "    fig=plt.figure(figsize=(5*columns, 4*rows))\n",
    "\n",
    "    for i in range(columns*rows):\n",
    "        image_name = '{}.png'.format(df.iloc[i,0])  \n",
    "        image_id = df.iloc[i,1]\n",
    "        img_path=data_dir+'/train_images/'\n",
    "        img_path=join(img_path,image_name)\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.title(image_id)\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "display_samples(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the data:\n",
    "class eye(Dataset):\n",
    "    def __init__(self,labels,directory,subset=False,transform=None):\n",
    "        self.labels=labels\n",
    "        self.directory=directory\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name='{}.png'.format(self.labels.iloc[idx,0])  \n",
    "        full_image_path=join(self.directory,img_name)\n",
    "        #print(f'\\nImage path:{full_image_path}')\n",
    "        #img = cv2.imread(img_name)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #image = self.transform(img)\n",
    "        #image = image['image']\n",
    "        image=Image.open(full_image_path)\n",
    "        image_resize = image.resize((224, 224), resample=Image.BILINEAR)\n",
    "        image=self.transform(image)\n",
    "        #image=image['image']\n",
    "        \n",
    "        image_label=self.labels.iloc[idx,1:].as_matrix().astype('float')\n",
    "        image_label=np.argmax(image_label)\n",
    "        \n",
    "        \n",
    "            \n",
    "        return [image,image_label]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDatasetTest(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join('../input/aptos2019-blindness-detection/test_images', self.data.loc[idx, 'id_code'] + '.png')\n",
    "        image = Image.open(img_name)\n",
    "        image = self.transform(image)\n",
    "        return {'image': image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class eyeTest(Dataset):\n",
    "#     def __init__(self,data,transform=None):\n",
    "#         self.data = data\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name='{}.png'.format(self.data.iloc[idx,0])  \n",
    "#         full_image_path=join(data_dir+'/test_images/',img_name)\n",
    "#         image=Image.open(full_image_path)\n",
    "#         image = image.resize((299, 299), resample=Image.BILINEAR)\n",
    "#         image=self.transform(image)\n",
    "#         return {'image': image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans=transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation(degrees=10),transforms.RandomVerticalFlip(),transforms.Resize((224,224)),transforms.ToTensor()])\n",
    "                                #transforms.Normalize(mean=[0.485,0.485,0.485],std=[0.485,0.485,0.485])])\n",
    "test_trans=transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
    "                                #transforms.RandomHorizontalFlip(),\n",
    "                                #transforms.RandomRotation(),\n",
    "                               # transforms.Normalize(mean=[0.485,0.485,0.485],std=[0.485,0.485,0.485])])\n",
    "# train_ds=eye(train_x,data_dir+'/train_images/',transform=train_trans)\n",
    "# valid_ds=eye(valid_x,data_dir+'/train_images/',transform=train_trans)\n",
    "# test_ds=eye(sample,data_dir+'/test_images/',transform=train_trans)\n",
    "\n",
    "# train_dl=DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "# valid_dl=DataLoader(valid_ds,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "# test_dl=DataLoader(test_ds,shuffle=True,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://github.com/anandsaha/pytorch.cyclic.learning.rate/blob/master/cls.py\n",
    "# This code is from https://github.com/thomasjpfan/pytorch/blob/401ec389db2c9d2978917a6e4d1101b20340d7e7/torch/optim/lr_scheduler.py\n",
    "# This code is under review at PyTorch and is to be merged eventually to make CLR available to all.\n",
    "# Tested with pytorch 0.2.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CyclicLR(object):\n",
    "    \"\"\"Sets the learning rate of each parameter group according to\n",
    "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
    "    rate between two boundaries with a constant frequency, as detailed in\n",
    "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
    "    The distance between the two boundaries can be scaled on a per-iteration\n",
    "    or per-cycle basis.\n",
    "    Cyclical learning rate policy changes the learning rate after every batch.\n",
    "    `batch_step` should be called after a batch has been used for training.\n",
    "    To resume training, save `last_batch_iteration` and use it to instantiate `CycleLR`.\n",
    "    This class has three built-in policies, as put forth in the paper:\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
    "        cycle iteration.\n",
    "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        base_lr (float or list): Initial learning rate which is the\n",
    "            lower boundary in the cycle for eachparam groups.\n",
    "            Default: 0.001\n",
    "        max_lr (float or list): Upper boundaries in the cycle for\n",
    "            each parameter group. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore\n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function. Default: 0.006\n",
    "        step_size (int): Number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch. Default: 2000\n",
    "        mode (str): One of {triangular, triangular2, exp_range}.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "            Default: 'triangular'\n",
    "        gamma (float): Constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "            Default: 1.0\n",
    "        scale_fn (function): Custom scaling policy defined by a single\n",
    "            argument lambda function, where\n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored\n",
    "            Default: None\n",
    "        scale_mode (str): {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on\n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle).\n",
    "            Default: 'cycle'\n",
    "        last_batch_iteration (int): The index of the last batch. Default: -1\n",
    "    Example:\n",
    "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "        >>> scheduler = torch.optim.CyclicLR(optimizer)\n",
    "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
    "        >>> for epoch in range(10):\n",
    "        >>>     for batch in data_loader:\n",
    "        >>>         scheduler.batch_step()\n",
    "        >>>         train_batch(...)\n",
    "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
    "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, base_lr=1e-5, max_lr=6e-5,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader):\n",
    "    total, correct = 0, 0\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs,aux = model(inputs)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs=15\n",
    "n_freeze=1\n",
    "n_folds=4\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_sampler,valid_sampler):\n",
    "    early_stopping = EarlyStopping(patience=2, verbose=True)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-5, momentum=0.99)\n",
    "    #learn_rate=CyclicLR(optimizer, base_lr=1e-5, max_lr=2e-5,step_size=40, mode='triangular2',gamma=0.99994)\n",
    "    \n",
    "    train_ds=eye(train_labels,data_dir+'/train_images/',transform=train_trans)\n",
    "    valid_ds=eye(train_labels,data_dir+'/train_images/',transform=test_trans)\n",
    "    \n",
    "    train=torch.utils.data.DataLoader(train_ds,batch_size=64,num_workers=4,sampler=train_sampler)\n",
    "    valid=torch.utils.data.DataLoader(valid_ds,batch_size=64,num_workers=4,sampler=valid_sampler)\n",
    "    #dataiter=iter(train)\n",
    "    #img,label=next(dataiter)\n",
    "    #print(\"\\n Shape of image\",img.shape)\n",
    "    #print(\"\\n Shape of label\",label[1].item())\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "       \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "                \n",
    "        print(time.ctime(),'Epoch:',epoch+1)\n",
    "        loss_arr=[]\n",
    "        loss_epoch_arr=[]\n",
    "        model.train()\n",
    "        for i,(inputs,labels) in enumerate(train,0):\n",
    "            #inputs=batch['image']\n",
    "            #labels=batch['label'].view(-1,1)\n",
    "        #inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #https://stackoverflow.com/questions/53476305/attributeerror-tuple-object-has-no-attribute-log-softmax\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            loss_arr.append(loss.item())\n",
    "        print(\"\\ntraining completed for epoch:\",epoch+1,\"Validation started at:\",time.ctime())\n",
    "        model.eval()\n",
    "        val_loss=[]\n",
    "        no_val_steps=0\n",
    "        for i,(input,label) in enumerate(valid,0):\n",
    "            #inputs=batch['image']\n",
    "            #labels=batch['label'].view(-1,1)\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                output=model(inputs)\n",
    "            \n",
    "            loss=criterion(output,labels)\n",
    "            val_loss.append(loss.item())\n",
    "            no_val_steps+=1\n",
    "            #learn_rate.batch_step(np.mean(val_loss))\n",
    "            #val_loss=val_loss/no_val_steps\n",
    "        print(f'Epoch {epoch+1} completed {time.ctime()} , train loss: {np.mean(loss_arr):.4f}, valid loss: {np.mean(val_loss):.4f}.')\n",
    "        early_stopping(np.mean(val_loss),model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "        \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    return(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train=len(train_labels)\n",
    "indices=list(range(num_train))\n",
    "kf=KFold(n_splits=n_folds,random_state=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = []\n",
    "valid_idx = []\n",
    "\n",
    "for t, v in kf.split(indices):\n",
    "    train_idx.append(t)\n",
    "    valid_idx.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = RetinopathyDatasetTest(\n",
    "    csv_file='../input/aptos2019-blindness-detection/sample_submission.csv', transform=test_trans)\n",
    "data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "  \n",
    "\n",
    "\n",
    "fold_predictions = np.zeros((len(test_dataset), n_folds))\n",
    "fold_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Sun Aug 11 06:48:48 2019 Epoch: 1\n",
      "\n",
      "training completed for epoch: 1 Validation started at: Sun Aug 11 06:54:09 2019\n",
      "Epoch 1 completed Sun Aug 11 06:55:23 2019 , train loss: 1.0103, valid loss: 0.1234.\n",
      "Validation loss decreased (inf --> 0.123447).  Saving model ...\n",
      "Fold: 1\n",
      "Sun Aug 11 06:56:20 2019 Epoch: 1\n",
      "\n",
      "training completed for epoch: 1 Validation started at: Sun Aug 11 07:01:42 2019\n",
      "Epoch 1 completed Sun Aug 11 07:02:52 2019 , train loss: 1.0299, valid loss: 0.1374.\n",
      "Validation loss decreased (inf --> 0.137440).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "for fold in np.arange(n_folds):\n",
    "    \n",
    "    print('Fold:',fold)\n",
    "    \n",
    "    # Model    \n",
    "\n",
    "    model=models.resnet50()\n",
    "    model.load_state_dict(torch.load(\"../input/pretrained-pytorch-models/resnet50-19c8e357.pth\"))\n",
    "    final_in_features=model.fc.in_features\n",
    "    model.fc=nn.Linear(final_in_features,5,bias=True)\n",
    "    model=model.to(device)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Train with early stopping\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx[fold])\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx[fold])\n",
    "\n",
    "    model = train_model(model,train_sampler,valid_sampler)\n",
    "    \n",
    "    # Inference for each CV split\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "   \n",
    "    test_preds = np.zeros((len(test_dataset), 1))  \n",
    "    \n",
    "   \n",
    "    \n",
    "    for i, x_batch in enumerate(data_loader_test):\n",
    "        x_batch = x_batch[\"image\"]\n",
    "        pred = model(x_batch.to(device))\n",
    "        test_preds[i * batch_size:(i + 1) * batch_size] = np.mean(pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1))\n",
    "                       \n",
    "    fold_predictions[:,fold] = test_preds.reshape(fold_predictions.shape[0])\n",
    "    \n",
    "    del(model, test_preds)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() \n",
    "    \n",
    "fold_predictions_avg = np.argmax(fold_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "# test_ds=eye(sample,data_dir+'/test_images/',transform=test_trans)\n",
    "# test=torch.utils.data.DataLoader(test_ds,num_workers=4,batch_size=batch_size,shuffle=False)\n",
    "# test_preds = np.zeros((len(test_ds), 1)) \n",
    "    \n",
    "# for i,(data,_) in enumerate(test):\n",
    "#         print(i)\n",
    "#         data=data.to(device)\n",
    "#         pred = model(data)\n",
    "#         test_preds[i * batch_size:(i + 1) * batch_size] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n",
    "                       \n",
    "# fold_predictions[:,fold] = test_preds.reshape(fold_predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# loss_arr = []\n",
    "# loss_epoch_arr = []\n",
    "# max_epochs = 3\n",
    "\n",
    "# for epoch in range(max_epochs):\n",
    "#     model.train()\n",
    "#     for i, (inputs,labels) in enumerate(train_dl,0):\n",
    "        \n",
    "#         #inputs, labels = data\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         with torch.set_grad_enabled(True):\n",
    "#         #https://stackoverflow.com/questions/53476305/attributeerror-tuple-object-has-no-attribute-log-softmax\n",
    "#             outputs,aux = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "        \n",
    "#         loss_arr.append(loss.item())\n",
    "        \n",
    "#     loss_epoch_arr.append(loss.item())\n",
    "        \n",
    "#     print('Epoch: %d/%d, Train acc: %0.2f, Valid acc: %0.2f' % (epoch, max_epochs, evaluation(train_dl), evaluation(valid_dl)))\n",
    "    \n",
    "    \n",
    "# plt.plot(loss_epoch_arr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds=eye(sample,data_dir+'/test_images/',transform=test_trans)\n",
    "# test=torch.utils.data.DataLoader(test_ds,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Taken from https://www.kaggle.com/ateplyuk/aptos-pytorch-starter-rnet50\n",
    "\n",
    "# # Prediction\n",
    "# predict = []\n",
    "# model.eval()\n",
    "# for i, (data, _) in enumerate(test):\n",
    "#     data = data.cuda()\n",
    "#     output = model(data)  \n",
    "#     output = output.cpu().detach().numpy()    \n",
    "#     predict.append(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmax(predict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005cfc8afb6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f0afdcd15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006efc72b638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836aaacf06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009245722fa4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  0005cfc8afb6          2\n",
       "1  003f0afdcd15          2\n",
       "2  006efc72b638          2\n",
       "3  00836aaacf06          2\n",
       "4  009245722fa4          2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['diagnosis'] = fold_predictions_avg\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1344\n",
       "3     584\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
